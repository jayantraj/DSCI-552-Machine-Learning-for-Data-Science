{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "colab": {
      "name": "HW-7(a)ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35ac66e7"
      },
      "source": [
        "## DSCI 552 : HomeWork 7-PartA\n",
        "\n",
        "### Name: Jayantraj CS (USC ID: 3993-1362-35)"
      ],
      "id": "35ac66e7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adcc8d53",
        "outputId": "5b226682-7ad1-431c-9969-c7f1b5096482"
      },
      "source": [
        "# Import Statements\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import os\n",
        "import warnings\n",
        "import seaborn as sns\n",
        "import random\n",
        "import math\n",
        "import time as t\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as k\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from skimage.color import rgb2gray\n",
        "from tensorflow.keras.layers import Dense,Dropout,LSTM\n",
        "from keras.utils import np_utils\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "plt.style.use('ggplot')\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)"
      ],
      "id": "adcc8d53",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ff24724"
      },
      "source": [
        "## *Question 1.) Generative Models for Text*"
      ],
      "id": "6ff24724"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edae1ac5"
      },
      "source": [
        "## *Question 1c.) LSTM: Train an LSTM to mimic Russell’s style and thoughts*"
      ],
      "id": "edae1ac5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2865819b"
      },
      "source": [
        "## *Question 1c.i.) Concatenate your text files to create a corpus of Russell’s writings*"
      ],
      "id": "2865819b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "281483a3"
      },
      "source": [
        "# gets all the file names in the given path.\n",
        "file_path='/content/drive/MyDrive/Colab Notebooks/HomeWork7/data/books/'\n",
        "file_names=[files for root,directories,files in os.walk(file_path)][0]\n",
        "corpus=[]\n",
        "for file in file_names:\n",
        "    b=open(file_path+ file, encoding='ascii', errors='ignore')\n",
        "    corpus.append(b.read().lower())"
      ],
      "id": "281483a3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43ac32df"
      },
      "source": [
        "## *Question 1c.ii.) Use a character-level representation for this model by using extended ASCII that has N = 256 characters*"
      ],
      "id": "43ac32df"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a0cd832",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21efd42e-2949-46c5-e592-363d7f1592a6"
      },
      "source": [
        "def character_representation(corpus_):\n",
        "    unique_chars=set()\n",
        "    char_ascii,ascii_char={},{}\n",
        "    max_ascii =-float('inf')\n",
        "    for book in corpus_:\n",
        "        unique_chars.update(list(set(book)))\n",
        "    total_num_of_uniq_chars=len(unique_chars)\n",
        "    print('Total number of unique characters :',total_num_of_uniq_chars)\n",
        "    for j in list(unique_chars):\n",
        "        #print(j,ord(j))\n",
        "        max_ascii=max(max_ascii,ord(j))\n",
        "        char_ascii[j]=ord(j)\n",
        "        ascii_char[ord(j)]=j\n",
        "    return char_ascii,ascii_char,max_ascii\n",
        "\n",
        "char_ascii,ascii_char,max_ascii=character_representation(corpus[:5])\n",
        "    "
      ],
      "id": "0a0cd832",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of unique characters : 68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUK9b5VgpWqV"
      },
      "source": [
        "Note: Since this is a large corpus for my computer’s power and it makes training LSTM hard(even with google colab pro), I will be using 5 books."
      ],
      "id": "jUK9b5VgpWqV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b8cf8c5"
      },
      "source": [
        "## *Question 1c.iii.) & 1c.iv.) Choose a window size, e.g., W = 100*"
      ],
      "id": "8b8cf8c5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a32b4e0"
      },
      "source": [
        "def choose_window(book_):\n",
        "    in_,out = [],[]\n",
        "    for i in range(0, len(book_)-100+1,1):\n",
        "        in_seq = book_[i : i + 100 - 1]\n",
        "        out_seq = book_[i + 100 - 1]\n",
        "        seq,val=[char_ascii[j] for j in in_seq],char_ascii[out_seq]\n",
        "        in_.append(seq)\n",
        "        out.append(val)\n",
        "    return in_, out,seq,val"
      ],
      "id": "6a32b4e0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "140e389d"
      },
      "source": [
        "def fun1(corpus_):\n",
        "    seq_in,seq_out=[],[]\n",
        "    for book in corpus_:\n",
        "        cur_in, cur_out,seq,val = choose_window(book)\n",
        "        seq_in.extend(cur_in)\n",
        "        seq_out.extend(cur_out)\n",
        "    return seq_in,seq_out"
      ],
      "id": "140e389d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca6913ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59198dd9-b971-4c8b-bf89-0fd3d54f28bb"
      },
      "source": [
        "start=t.time()\n",
        "seq_in,seq_out = fun1(corpus[:5])\n",
        "#print(len(seq_in))\n",
        "end=t.time()\n",
        "print(\"Time Taken for Execution:\",end-start)"
      ],
      "id": "ca6913ba",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time Taken for Execution: 31.73745346069336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c6715a3"
      },
      "source": [
        "## *Question 1c.v.) Rescaling or Normalizing the input and One-Hot encode the output*"
      ],
      "id": "5c6715a3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKLsTQjlJ69b"
      },
      "source": [
        "def return_one_hot_encode_array(seq_in,seq_out,max_ascii):\n",
        "  input_lstm = np.reshape(seq_in,(len(seq_in),100-1,1))\n",
        "  input_lstm = input_lstm / max_ascii\n",
        "  output_lstm = np_utils.to_categorical(seq_out)\n",
        "  return input_lstm,output_lstm"
      ],
      "id": "uKLsTQjlJ69b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac32cdcb",
        "outputId": "0f7d01c3-8936-4ef8-eced-d73c48b0ec25"
      },
      "source": [
        "start=t.time()\n",
        "input_lstm,output_lstm=return_one_hot_encode_array(seq_in,seq_out,max_ascii)\n",
        "print('The shape of the input :',input_lstm.shape)\n",
        "print('The shape of the output :',output_lstm.shape)\n",
        "end=t.time()\n",
        "print(\"Time Taken for Execution:\",end-start)"
      ],
      "id": "ac32cdcb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of the input : (2683450, 99, 1)\n",
            "The shape of the output : (2683450, 127)\n",
            "Time Taken for Execution: 45.59769654273987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5cY2jH5sS1y",
        "outputId": "b597e2a2-f8a2-4397-f4f1-6cdd6ee4f1ca"
      },
      "source": [
        "# Verifying whether the input is normalized.\n",
        "# We can see that the values are rescaled between [0,1].\n",
        "print(input_lstm[0][:5])"
      ],
      "id": "l5cY2jH5sS1y",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.78571429]\n",
            " [0.82539683]\n",
            " [0.76984127]\n",
            " [0.88888889]\n",
            " [0.92063492]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a03c96e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64cc1efe-e491-4a2b-836a-e4910d021bb9"
      },
      "source": [
        "print(min(seq_out),max(seq_out))"
      ],
      "id": "a03c96e0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uggim7as3rT"
      },
      "source": [
        "We can see that the maximum ASCII value for the output vector is 126. This means after one-hot encoding the output vector will be a vector of size 127(0-126). Any one of the indexes 0-126 will become 1 if it corresponds to the character. This justifies, why our ouput_lstm vector has a shape (2683450, 127)."
      ],
      "id": "5uggim7as3rT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dd71ae1"
      },
      "source": [
        "## *Questions 1c.vi - c.x.) Building the LSTM model*"
      ],
      "id": "7dd71ae1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ea2d772a"
      },
      "source": [
        "model_lstm = Sequential()\n",
        "x,y=input_lstm.shape[1],input_lstm.shape[2]"
      ],
      "id": "ea2d772a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcfa429f"
      },
      "source": [
        "model_lstm.add(LSTM(256,input_shape=(x,y)))\n",
        "model_lstm.add(Dropout(0.2))\n"
      ],
      "id": "fcfa429f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd483c86"
      },
      "source": [
        "model_lstm.add(Dense(output_lstm.shape[1], activation='softmax'))\n",
        "model_lstm.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "id": "dd483c86",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRp1rQ4avWO6"
      },
      "source": [
        " \n",
        "\n",
        "*   Log loss or Cross-entropy as the objective function of the network. Log loss and Cross-entropy are essentially the same. Typically, we will use the term log loss for binary classification problems, and cross-entropy loss for multiclass-classification problems. But they can be used synonymously.\n",
        "\n",
        "*   cross-entropy loss measures the performance of a classification model whose output is a probability value between 0 and 1.\n",
        "\n",
        "*   When we are adjusting or changing weights during training(like our case), cross-entropy loss is used. The goal is to reduce or minimize the loss, the model which has the smallest loss is the better model.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "LRp1rQ4avWO6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fR6hqlWQuMYp",
        "outputId": "fe16e433-eeb8-4a39-ad42-a414bf6d5dd3"
      },
      "source": [
        "print(model_lstm.summary())"
      ],
      "id": "fR6hqlWQuMYp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_1 (LSTM)               (None, 256)               264192    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 127)               32639     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 296,831\n",
            "Trainable params: 296,831\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd684a03"
      },
      "source": [
        "weights_file_path='/content/drive/MyDrive/Colab Notebooks/HomeWork7'\n",
        "cp = ModelCheckpoint(weights_file_path+\"/weights/loss_value{loss:}.hdf5\", monitor='loss', verbose=1, save_best_only=True, mode='min')"
      ],
      "id": "dd684a03",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c218a90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "752b28b7-358c-4b17-e0cc-f353d351ed61"
      },
      "source": [
        "start =t.time()\n",
        "model_lstm.fit(input_lstm, output_lstm, epochs=30, batch_size=64, callbacks=[cp])\n",
        "end=t.time()\n",
        "print(\"Time Taken for Execution:\",end-start)"
      ],
      "id": "0c218a90",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "41926/41929 [============================>.] - ETA: 0s - loss: 2.6672\n",
            "Epoch 00001: loss improved from inf to 2.66720, saving model to /content/drive/MyDrive/Colab Notebooks/HomeWork7/weights/loss_value2.6672046184539795.hdf5\n",
            "41929/41929 [==============================] - 484s 11ms/step - loss: 2.6672\n",
            "Epoch 2/30\n",
            "41925/41929 [============================>.] - ETA: 0s - loss: 2.3422\n",
            "Epoch 00002: loss improved from 2.66720 to 2.34214, saving model to /content/drive/MyDrive/Colab Notebooks/HomeWork7/weights/loss_value2.3421361446380615.hdf5\n",
            "41929/41929 [==============================] - 479s 11ms/step - loss: 2.3421\n",
            "Epoch 3/30\n",
            "41926/41929 [============================>.] - ETA: 0s - loss: 2.1642\n",
            "Epoch 00003: loss improved from 2.34214 to 2.16418, saving model to /content/drive/MyDrive/Colab Notebooks/HomeWork7/weights/loss_value2.164184093475342.hdf5\n",
            "41929/41929 [==============================] - 478s 11ms/step - loss: 2.1642\n",
            "Epoch 4/30\n",
            "41926/41929 [============================>.] - ETA: 0s - loss: 2.0609\n",
            "Epoch 00004: loss improved from 2.16418 to 2.06089, saving model to /content/drive/MyDrive/Colab Notebooks/HomeWork7/weights/loss_value2.060885190963745.hdf5\n",
            "41929/41929 [==============================] - 478s 11ms/step - loss: 2.0609\n",
            "Epoch 5/30\n",
            "41927/41929 [============================>.] - ETA: 0s - loss: 2.0137\n",
            "Epoch 00005: loss improved from 2.06089 to 2.01365, saving model to /content/drive/MyDrive/Colab Notebooks/HomeWork7/weights/loss_value2.0136501789093018.hdf5\n",
            "41929/41929 [==============================] - 477s 11ms/step - loss: 2.0137\n",
            "Epoch 6/30\n",
            "41925/41929 [============================>.] - ETA: 0s - loss: 1.9606\n",
            "Epoch 00006: loss improved from 2.01365 to 1.96059, saving model to /content/drive/MyDrive/Colab Notebooks/HomeWork7/weights/loss_value1.9605931043624878.hdf5\n",
            "41929/41929 [==============================] - 477s 11ms/step - loss: 1.9606\n",
            "Epoch 7/30\n",
            "41929/41929 [==============================] - ETA: 0s - loss: 1.9206\n",
            "Epoch 00007: loss improved from 1.96059 to 1.92058, saving model to /content/drive/MyDrive/Colab Notebooks/HomeWork7/weights/loss_value1.9205759763717651.hdf5\n",
            "41929/41929 [==============================] - 478s 11ms/step - loss: 1.9206\n",
            "Epoch 8/30\n",
            "41926/41929 [============================>.] - ETA: 0s - loss: 1.8892\n",
            "Epoch 00008: loss improved from 1.92058 to 1.88923, saving model to /content/drive/MyDrive/Colab Notebooks/HomeWork7/weights/loss_value1.8892284631729126.hdf5\n",
            "41929/41929 [==============================] - 477s 11ms/step - loss: 1.8892\n",
            "Epoch 9/30\n",
            "41926/41929 [============================>.] - ETA: 0s - loss: 1.9555\n",
            "Epoch 00009: loss did not improve from 1.88923\n",
            "41929/41929 [==============================] - 479s 11ms/step - loss: 1.9555\n",
            "Epoch 10/30\n",
            "41927/41929 [============================>.] - ETA: 0s - loss: 1.8747\n",
            "Epoch 00010: loss improved from 1.88923 to 1.87470, saving model to /content/drive/MyDrive/Colab Notebooks/HomeWork7/weights/loss_value1.874703049659729.hdf5\n",
            "41929/41929 [==============================] - 480s 11ms/step - loss: 1.8747\n",
            "Epoch 11/30\n",
            "41927/41929 [============================>.] - ETA: 0s - loss: 1.8361\n",
            "Epoch 00011: loss improved from 1.87470 to 1.83609, saving model to /content/drive/MyDrive/Colab Notebooks/HomeWork7/weights/loss_value1.8360891342163086.hdf5\n",
            "41929/41929 [==============================] - 480s 11ms/step - loss: 1.8361\n",
            "Epoch 12/30\n",
            "41928/41929 [============================>.] - ETA: 0s - loss: 1.8170\n",
            "Epoch 00012: loss improved from 1.83609 to 1.81698, saving model to /content/drive/MyDrive/Colab Notebooks/HomeWork7/weights/loss_value1.8169816732406616.hdf5\n",
            "41929/41929 [==============================] - 479s 11ms/step - loss: 1.8170\n",
            "Epoch 13/30\n",
            "41925/41929 [============================>.] - ETA: 0s - loss: 1.8038\n",
            "Epoch 00013: loss improved from 1.81698 to 1.80378, saving model to /content/drive/MyDrive/Colab Notebooks/HomeWork7/weights/loss_value1.8037787675857544.hdf5\n",
            "41929/41929 [==============================] - 477s 11ms/step - loss: 1.8038\n",
            "Epoch 14/30\n",
            "41929/41929 [==============================] - ETA: 0s - loss: 1.7886\n",
            "Epoch 00014: loss improved from 1.80378 to 1.78857, saving model to /content/drive/MyDrive/Colab Notebooks/HomeWork7/weights/loss_value1.7885719537734985.hdf5\n",
            "41929/41929 [==============================] - 479s 11ms/step - loss: 1.7886\n",
            "Epoch 15/30\n",
            "41929/41929 [==============================] - ETA: 0s - loss: 1.7767\n",
            "Epoch 00015: loss improved from 1.78857 to 1.77675, saving model to /content/drive/MyDrive/Colab Notebooks/HomeWork7/weights/loss_value1.7767491340637207.hdf5\n",
            "41929/41929 [==============================] - 479s 11ms/step - loss: 1.7767\n",
            "Epoch 16/30\n",
            "41925/41929 [============================>.] - ETA: 0s - loss: 1.7639\n",
            "Epoch 00016: loss improved from 1.77675 to 1.76390, saving model to /content/drive/MyDrive/Colab Notebooks/HomeWork7/weights/loss_value1.7639013528823853.hdf5\n",
            "41929/41929 [==============================] - 479s 11ms/step - loss: 1.7639\n",
            "Epoch 17/30\n",
            "41925/41929 [============================>.] - ETA: 0s - loss: 1.7591\n",
            "Epoch 00017: loss improved from 1.76390 to 1.75913, saving model to /content/drive/MyDrive/Colab Notebooks/HomeWork7/weights/loss_value1.7591348886489868.hdf5\n",
            "41929/41929 [==============================] - 477s 11ms/step - loss: 1.7591\n",
            "Epoch 18/30\n",
            "41929/41929 [==============================] - ETA: 0s - loss: 1.7435\n",
            "Epoch 00018: loss improved from 1.75913 to 1.74352, saving model to /content/drive/MyDrive/Colab Notebooks/HomeWork7/weights/loss_value1.7435165643692017.hdf5\n",
            "41929/41929 [==============================] - 478s 11ms/step - loss: 1.7435\n",
            "Epoch 19/30\n",
            "41928/41929 [============================>.] - ETA: 0s - loss: 1.7380\n",
            "Epoch 00019: loss improved from 1.74352 to 1.73800, saving model to /content/drive/MyDrive/Colab Notebooks/HomeWork7/weights/loss_value1.738000512123108.hdf5\n",
            "41929/41929 [==============================] - 478s 11ms/step - loss: 1.7380\n",
            "Epoch 20/30\n",
            "41927/41929 [============================>.] - ETA: 0s - loss: 1.7281\n",
            "Epoch 00020: loss improved from 1.73800 to 1.72806, saving model to /content/drive/MyDrive/Colab Notebooks/HomeWork7/weights/loss_value1.7280621528625488.hdf5\n",
            "41929/41929 [==============================] - 478s 11ms/step - loss: 1.7281\n",
            "Epoch 21/30\n",
            "41927/41929 [============================>.] - ETA: 0s - loss: 1.7187\n",
            "Epoch 00021: loss improved from 1.72806 to 1.71868, saving model to /content/drive/MyDrive/Colab Notebooks/HomeWork7/weights/loss_value1.7186806201934814.hdf5\n",
            "41929/41929 [==============================] - 480s 11ms/step - loss: 1.7187\n",
            "Epoch 22/30\n",
            "41925/41929 [============================>.] - ETA: 0s - loss: 1.7229\n",
            "Epoch 00022: loss did not improve from 1.71868\n",
            "41929/41929 [==============================] - 478s 11ms/step - loss: 1.7230\n",
            "Epoch 23/30\n",
            "41929/41929 [==============================] - ETA: 0s - loss: 2.7946\n",
            "Epoch 00023: loss did not improve from 1.71868\n",
            "41929/41929 [==============================] - 478s 11ms/step - loss: 2.7946\n",
            "Epoch 24/30\n",
            "41928/41929 [============================>.] - ETA: 0s - loss: 2.6246\n",
            "Epoch 00024: loss did not improve from 1.71868\n",
            "41929/41929 [==============================] - 479s 11ms/step - loss: 2.6246\n",
            "Epoch 25/30\n",
            "41928/41929 [============================>.] - ETA: 0s - loss: 2.6283\n",
            "Epoch 00025: loss did not improve from 1.71868\n",
            "41929/41929 [==============================] - 478s 11ms/step - loss: 2.6283\n",
            "Epoch 26/30\n",
            "41928/41929 [============================>.] - ETA: 0s - loss: 2.1751\n",
            "Epoch 00026: loss did not improve from 1.71868\n",
            "41929/41929 [==============================] - 478s 11ms/step - loss: 2.1751\n",
            "Epoch 27/30\n",
            "41927/41929 [============================>.] - ETA: 0s - loss: 1.9524\n",
            "Epoch 00027: loss did not improve from 1.71868\n",
            "41929/41929 [==============================] - 478s 11ms/step - loss: 1.9524\n",
            "Epoch 28/30\n",
            "41928/41929 [============================>.] - ETA: 0s - loss: 1.8734\n",
            "Epoch 00028: loss did not improve from 1.71868\n",
            "41929/41929 [==============================] - 478s 11ms/step - loss: 1.8734\n",
            "Epoch 29/30\n",
            "41926/41929 [============================>.] - ETA: 0s - loss: 1.8274\n",
            "Epoch 00029: loss did not improve from 1.71868\n",
            "41929/41929 [==============================] - 478s 11ms/step - loss: 1.8274\n",
            "Epoch 30/30\n",
            "41927/41929 [============================>.] - ETA: 0s - loss: 1.7954\n",
            "Epoch 00030: loss did not improve from 1.71868\n",
            "41929/41929 [==============================] - 479s 11ms/step - loss: 1.7954\n",
            "Time Taken for Execution: 14358.512123346329\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OF1o1W91z8OT"
      },
      "source": [
        "## *Question 1c.xi.) Use the network with the best weights to generate 1000 characters, using the given text.*"
      ],
      "id": "OF1o1W91z8OT"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQuRGfjF5jOj"
      },
      "source": [
        "def get_the_ascii_list(text):\n",
        "  result=[]\n",
        "  for i in text:\n",
        "    result.append(char_ascii[i])\n",
        "  return result\n",
        "\n",
        "text ='There are those who take mental phenomena naively, just as they would physical phenomena. This school of psychologists tends not to emphasize the object.'\n",
        "ascii_text=get_the_ascii_list(text[-99:].lower())\n"
      ],
      "id": "MQuRGfjF5jOj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0459f392",
        "outputId": "36b719fe-65f9-4456-c07d-5412ad8b65b5"
      },
      "source": [
        "new_text=0\n",
        "for i in range(1000):\n",
        "  r=len(ascii_text)\n",
        "  new_text = np.reshape(ascii_text, (1, r, 1))\n",
        "  new_text = new_text / max_ascii\n",
        "  character_predicted = model_lstm.predict(new_text, verbose=0)\n",
        "  index_predicted = np.argmax(character_predicted)\n",
        "  text=text+ ascii_char[index_predicted]\n",
        "  ascii_text.append(index_predicted)\n",
        "  q=len(ascii_text)\n",
        "  ascii_text = ascii_text[1:q]\n",
        "print(text)"
      ],
      "id": "0459f392",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are those who take mental phenomena naively, just as they would physical phenomena. This school of psychologists tends not to emphasize the object.\n",
            "the semsetive perception of the semse dnrsel to the semsetive poonssi\n",
            "of the semsetive poonssi of the semsetive poonssi of the semsetive poonss\n",
            "of the semse- and thete are the semsetian aosteee of the semsetive poonss\n",
            "of the semse- and thete are the semsetian aosteee of the semsetive poonss\n",
            "of the semse- and thete are the semsetian aosteee of the semsetive poonss\n",
            "of the semse- and thete are the semsetian aosteee of the semsetive poonss\n",
            "of the semse- and thete are the semsetian aosteee of the semsetive poonss\n",
            "of the semse- and thete are the semsetian aosteee of the semsetive poonss\n",
            "of the semse- and thete are the semsetian aosteee of the semsetive poonss\n",
            "of the semse- and thete are the semsetian aosteee of the semsetive poonss\n",
            "of the semse- and thete are the semsetian aosteee of the semsetive poonss\n",
            "of the semse- and thete are the semsetian aosteee of the semsetive poonss\n",
            "of the semse- and thete are the semsetian aosteee of the semsetive poonss\n",
            "of the semse- and thete are the semsetian\n"
          ]
        }
      ]
    }
  ]
}